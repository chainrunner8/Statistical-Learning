{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: after experimenting I realised np.diag() only creates a \n",
    "# strided view of the original data, not a regular 2D array, so \n",
    "# to make operations on it I need to add a float to it (here 0.2), \n",
    "# or just '+ 0.'\n",
    "p = 3\n",
    "\n",
    "def generateData(n):\n",
    "    n1 = n2 = n//2\n",
    "    cov_1 = np.diag(np.repeat(1, p)) + 0.2\n",
    "    cov_2 = np.diag(np.repeat(1, p)) + 0.2\n",
    "    cov_2[1, 2] = cov_2[2, 1] = cov_2[1, 2] + 0.5\n",
    "    x_class1 = np.random.multivariate_normal(\n",
    "        mean=np.repeat(3, p),\n",
    "        cov=cov_1,\n",
    "        size=n1\n",
    "    )\n",
    "    x_class2 = np.random.multivariate_normal(\n",
    "        mean=np.repeat(2, p),\n",
    "        cov=cov_2,\n",
    "        size=n2\n",
    "    )\n",
    "    y = np.repeat((1, 2), (n1, n2))\n",
    "    data_set = pd.concat([pd.DataFrame(x_class1), pd.DataFrame(x_class2)])\n",
    "    data_set.columns = [f'x_{i}' for i in range(1, p+1)]\n",
    "    data_set['y'] = y\n",
    "\n",
    "    return data_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the covariance matrices are the same for both classes, it follows the assumption that the validity (or let's say the performance) of LDA depends upon, so the bias is low. In this case, LDA might be the best performing classifier, while QDA would have have a higher variance would be too flexible for our data set here (given that the Bayes decision boundary is linear)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "\n",
    "\n",
    "def predictLDA(train_set, test_set):\n",
    "\n",
    "    LDA = LinearDiscriminantAnalysis()\n",
    "    LDA.fit(\n",
    "        X=train_set[[f'x_{i}' for i in range(1, p+1)]], \n",
    "        y=train_set['y']\n",
    "    )\n",
    "    # let's first take a quick look at what's inside our LDA:\n",
    "    # print(\"LDA Classes:\", LDA.classes_)\n",
    "    # print(\"LDA Means:\", LDA.means_)\n",
    "    # print(\"LDA Covariance matrix:\", LDA.covariance_)\n",
    "\n",
    "    y_pred = LDA.predict(X=test_set[[f'x_{i}' for i in range(1, p+1)]])\n",
    "\n",
    "    return y_pred\n",
    "\n",
    "\n",
    "def predictQDA(train_set, test_set):\n",
    "    \n",
    "    QDA = QuadraticDiscriminantAnalysis()\n",
    "    QDA.fit(\n",
    "        X=train_set[[f'x_{i}' for i in range(1, p+1)]], \n",
    "        y=train_set['y']\n",
    "    )\n",
    "    # let's first take a quick look at what's inside our QDA:\n",
    "    # print(\"QDA Classes:\", QDA.classes_)\n",
    "    # print(\"QDA Means:\", QDA.means_)\n",
    "    # print(\"QDA Covariance matrix:\", QDA.covariance_)\n",
    "\n",
    "    y_pred = QDA.predict(X=test_set[[f'x_{i}' for i in range(1, p+1)]])\n",
    "\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's generate two small data sets and take a look at what our discriminant functions do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = generateData(20)\n",
    "test = generateData(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA Classes: [1 2]\n",
      "LDA Means: [[3.22560067 2.39104093 3.38032654]\n",
      " [2.03234439 1.7851859  1.72716202]]\n",
      "LDA Covariance matrix: [[ 1.13749041 -0.21471272 -0.20747685]\n",
      " [-0.21471272  0.70179146 -0.1659123 ]\n",
      " [-0.20747685 -0.1659123   0.94067546]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gaspard\\miniconda3\\envs\\venv_stats\\Lib\\site-packages\\sklearn\\utils\\validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 2, 1, 1, 1, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictLDA(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QDA Classes: [1 2]\n",
      "QDA Means: [[3.22560067 2.39104093 3.38032654]\n",
      " [2.03234439 1.7851859  1.72716202]]\n",
      "QDA Covariance matrix: [array([[ 0.94555935, -0.23851467,  0.08941347],\n",
      "       [-0.23851467,  0.4644733 , -0.49326297],\n",
      "       [ 0.08941347, -0.49326297,  1.17158881]]), array([[ 1.58219712, -0.23862471, -0.55047315],\n",
      "       [-0.23862471,  1.09506328,  0.12456897],\n",
      "       [-0.55047315,  0.12456897,  0.91880109]])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Gaspard\\miniconda3\\envs\\venv_stats\\Lib\\site-packages\\sklearn\\utils\\validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 2, 2, 1, 1, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictQDA(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the QDA function returned two covariances matrices. Also notice how the fifth elements of the ```y_pred``` results differ betwee the two methods, but the rest of the predicted labels are the same.\n",
    "\n",
    "I have now removed the ```store_covariance=True``` parameter and commented out the print statements in the discriminant functions, to prepare for the loop we are going to be running next.\n",
    "\n",
    "Below I manually coded a function that computes the confusion matrix and returns the accuracy, for the challenge:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifyPreds(row):\n",
    "    \n",
    "    if row.y == 2 and row.y_hat == 2:\n",
    "        return 'TP'\n",
    "    elif row.y == 2 and row.y_hat == 1:\n",
    "        return 'FN'\n",
    "    elif row.y == 1 and row.y_hat == 2:\n",
    "        return 'FP'\n",
    "    elif row.y == 1 and row.y_hat == 1:\n",
    "        return 'TN'\n",
    "\n",
    "\n",
    "def getAccuracy(df_labels):\n",
    "\n",
    "    pos_negs = df_labels.apply(classifyPreds, axis=1)\n",
    "    cf_matrix = pos_negs.value_counts()\n",
    "    return (cf_matrix['TP'] + cf_matrix['TN']) / sum(cf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now the function that is going to run the experiment 100 times and return the average accuracy over these 100 repetitions for both methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import fmean\n",
    "\n",
    "\n",
    "def discriminantAnalysis(n_train):\n",
    "    \n",
    "    classifier_acc = {'LDA': [], 'QDA': []}\n",
    "\n",
    "    for _ in range(100):\n",
    "        train = generateData(n_train)\n",
    "        test = generateData(10_000)\n",
    "\n",
    "        y_hat_LDA = predictLDA(train, test)\n",
    "        y_hat_QDA = predictQDA(train, test)\n",
    "\n",
    "        df_LDA = pd.DataFrame({'y': test['y'], 'y_hat': y_hat_LDA})\n",
    "        df_QDA = pd.DataFrame({'y': test['y'], 'y_hat': y_hat_QDA})\n",
    "\n",
    "        classifier_acc['LDA'].append(getAccuracy(df_LDA))\n",
    "        classifier_acc['QDA'].append(getAccuracy(df_QDA))\n",
    "\n",
    "    return pd.DataFrame({'LDA': [round(fmean(classifier_acc['LDA']), 4)], 'QDA': [round(fmean(classifier_acc['QDA']), 4)]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LDA</th>\n",
       "      <th>QDA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>n_train=50</th>\n",
       "      <td>0.7276</td>\n",
       "      <td>0.7264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_train=10^4</th>\n",
       "      <td>0.7446</td>\n",
       "      <td>0.7577</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 LDA     QDA\n",
       "n_train=50    0.7276  0.7264\n",
       "n_train=10^4  0.7446  0.7577"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_50 = discriminantAnalysis(50)\n",
    "df_train_10k = discriminantAnalysis(10_000)\n",
    "\n",
    "df_results = pd.concat([df_train_50, df_train_10k])\n",
    "df_results.index = pd.Index(['n_train=50', 'n_train=10^4'])\n",
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the table above, we see that for ```n_train = 50```, over 100 repetitions, LDA and QDA have virtually the same accuracy. I would say this result here is not exactly in line with my expectations because with as few as 50 training observations, I would have expected LDA to perform better because it has lower variance and also the distributions of our X predictors in both classes have the same covariance matrix. For ```n_train = 10,000``` though, we see that QDA barely outperforms LDA: I cannot say I am surprised at this result this time because with such a bigger training set, our models can \"see\" most of the variance in the data, and having a more flexible model is less of an issue in this case and it also has lower bias. Even with this training set size, QDA does not vastly outperform LDA, because once again the assumption of equal covariance matrices perfectly holds."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_stats",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
